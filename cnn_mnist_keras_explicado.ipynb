{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# CNN em Keras para MNIST (Reprodução do Artigo)\n", "\n", "Este notebook implementa, em **TensorFlow/Keras**, a CNN descrita no artigo\n", "\n", "> *AN OPTIMIZED CONVOLUTIONAL NEURAL NETWORK FOR HANDWRITTEN DIGITAL RECOGNITION CLASSIFICATION*\n", "\n", "Aqui fazemos:\n", "\n", "1. Preparação do dataset MNIST  \n", "2. Definição de um modelo CNN com profundidade variável (1, 2 ou 3 blocos Conv+Pool)  \n", "3. Treinamento com **5-fold cross-validation**  \n", "4. Experimentos variando:\n", "   - **taxa de aprendizagem (learning rate)**  \n", "   - **número de épocas (epochs)**  \n", "   - **profundidade da rede (número de blocos Conv+Pool)**  \n", "5. Geração de **gráficos** para análise visual dos resultados."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Imports principais\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "\n", "from tensorflow.keras.datasets import mnist\n", "from tensorflow.keras.models import Sequential\n", "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n", "from tensorflow.keras.optimizers import SGD\n", "from tensorflow.keras.utils import to_categorical\n", "from sklearn.model_selection import KFold"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1. Carregando e preparando o dataset MNIST\n", "\n", "- Imagens 28x28 em escala de cinza (0–255)  \n", "- Normalizamos para o intervalo **[0, 1]**  \n", "- Adicionamos um eixo de canal para ficar no formato `(28, 28, 1)`  \n", "- Codificamos os rótulos em *one-hot* (10 classes: dígitos de 0 a 9)."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Carregar MNIST\n", "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n", "\n", "# Normalização para [0,1]\n", "x_train = x_train.astype(\"float32\") / 255.0\n", "x_test = x_test.astype(\"float32\") / 255.0\n", "\n", "# Adicionar eixo de canal (grayscale)\n", "x_train = np.expand_dims(x_train, axis=-1)\n", "x_test = np.expand_dims(x_test, axis=-1)\n", "\n", "# One-hot encoding dos rótulos\n", "num_classes = 10\n", "y_train_cat = to_categorical(y_train, num_classes)\n", "y_test_cat = to_categorical(y_test, num_classes)\n", "\n", "x_train.shape, y_train_cat.shape"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2. Definição do modelo CNN (com profundidade variável)\n", "\n", "O artigo trabalha com a ideia de **profundidade** da rede como o número de blocos:\n", "\n", "> bloco = `Conv2D → ReLU → MaxPooling2D`\n", "\n", "Assim, temos:\n", "\n", "- **1 bloco** → rede mais rasa  \n", "- **2 blocos** → rede moderadamente profunda (melhor desempenho no artigo)  \n", "- **3 blocos** → rede mais profunda (piora um pouco o desempenho)  \n", "\n", "Após os blocos, usamos:\n", "\n", "- `Flatten` para achatar o mapa de características em um vetor  \n", "- `Dense(128, ReLU)` para interpretação das features  \n", "- `Dense(10, Softmax)` para classificação em 10 dígitos."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["def create_cnn_model(num_blocks=1, learning_rate=0.01, momentum=0.9):\n", "    \"\"\"Cria a CNN conforme a descrição do artigo, com num_blocks blocos Conv+Pool.\"\"\"\n", "    model = Sequential()\n", "\n", "    # Primeiro bloco Conv+Pool (com shape de entrada definido)\n", "    model.add(\n", "        Conv2D(\n", "            filters=32,\n", "            kernel_size=(3, 3),\n", "            activation=\"relu\",\n", "            input_shape=(28, 28, 1),\n", "        )\n", "    )\n", "    model.add(MaxPooling2D(pool_size=(2, 2)))\n", "\n", "    # Blocos adicionais (para profundidade 2 ou 3)\n", "    for _ in range(num_blocks - 1):\n", "        model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n", "        model.add(MaxPooling2D(pool_size=(2, 2)))\n", "\n", "    # Classificador\n", "    model.add(Flatten())\n", "    model.add(Dense(128, activation=\"relu\"))  # tamanho não especificado no artigo\n", "    model.add(Dense(10, activation=\"softmax\"))\n", "\n", "    # Otimizador SGD com momentum (como no artigo)\n", "    optimizer = SGD(learning_rate=learning_rate, momentum=momentum)\n", "\n", "    model.compile(\n", "        optimizer=optimizer,\n", "        loss=\"categorical_crossentropy\",\n", "        metrics=[\"accuracy\"],\n", "    )\n", "\n", "    return model\n", "\n", "# Exemplo: modelo raso com 1 bloco\n", "model_example = create_cnn_model(num_blocks=1)\n", "model_example.summary()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3. Funções de treino e avaliação com 5-fold cross-validation\n", "\n", "O artigo utiliza **5-fold cross-validation** para:\n", "\n", "- Reduzir variância na avaliação  \n", "- Obter **média** e **desvio padrão** da acurácia  \n", "\n", "Vamos implementar uma função que:\n", "\n", "- Recebe `num_blocks`, `learning_rate`, `epochs`  \n", "- Faz o *split* em 5 folds  \n", "- Treina o modelo em cada fold  \n", "- Retorna acurácia média e desvio padrão em %"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["def run_kfold(num_blocks, learning_rate, epochs, batch_size=32, verbose=0):\n", "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n", "    accuracies = []\n", "\n", "    for train_idx, val_idx in kf.split(x_train):\n", "        x_tr, x_val = x_train[train_idx], x_train[val_idx]\n", "        y_tr, y_val = y_train_cat[train_idx], y_train_cat[val_idx]\n", "\n", "        model = create_cnn_model(\n", "            num_blocks=num_blocks,\n", "            learning_rate=learning_rate,\n", "            momentum=0.9,\n", "        )\n", "        model.fit(\n", "            x_tr,\n", "            y_tr,\n", "            epochs=epochs,\n", "            batch_size=batch_size,\n", "            verbose=verbose,\n", "        )\n", "\n", "        loss, acc = model.evaluate(x_val, y_val, verbose=0)\n", "        accuracies.append(acc * 100.0)\n", "\n", "    return float(np.mean(accuracies)), float(np.std(accuracies))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4. Experimento 1 – Variando a profundidade da rede\n", "\n", "Aqui reproduzimos o experimento de **profundidade (model depth)**:\n", "\n", "- Testamos **1, 2 e 3 blocos Conv+Pool**  \n", "- Mantemos:\n", "  - `learning_rate = 0.01`  \n", "  - `epochs = 10` (baseline)  \n", "\n", "Em seguida, ploteremos um gráfico de barras com a acurácia média de cada configuração."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["depths = [1, 2, 3]\n", "depth_means = []\n", "depth_stds = []\n", "\n", "for d in depths:\n", "    mean_acc, std_acc = run_kfold(num_blocks=d, learning_rate=0.01, epochs=10, verbose=0)\n", "    depth_means.append(mean_acc)\n", "    depth_stds.append(std_acc)\n", "    print(f\"Profundidade {d} blocos: média = {mean_acc:.3f}%, desvio = {std_acc:.3f}%\")"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Gráfico: acurácia média x profundidade\n", "plt.figure()\n", "x_pos = np.arange(len(depths))\n", "plt.bar(x_pos, depth_means, yerr=depth_stds)\n", "plt.xticks(x_pos, [str(d) for d in depths])\n", "plt.xlabel(\"Número de blocos Conv+Pool (profundidade)\")\n", "plt.ylabel(\"Acurácia média (%)\")\n", "plt.title(\"Acurácia vs Profundidade da CNN (5-fold)\")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5. Experimento 2 – Variando o *learning rate*\n", "\n", "Agora avaliamos o impacto do **learning rate**:\n", "\n", "- Mantemos:\n", "  - 1 bloco Conv+Pool (modelo baseline)  \n", "  - 10 épocas  \n", "- Testamos os valores usados no artigo:\n", "  - 0.01, 0.05, 0.08, 0.10, 0.15  \n", "\n", "Em seguida, ploteremos um gráfico com a acurácia média por valor de learning rate."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["lrs = [0.01, 0.05, 0.08, 0.1, 0.15]\n", "lr_means = []\n", "lr_stds = []\n", "\n", "for lr in lrs:\n", "    mean_acc, std_acc = run_kfold(num_blocks=1, learning_rate=lr, epochs=10, verbose=0)\n", "    lr_means.append(mean_acc)\n", "    lr_stds.append(std_acc)\n", "    print(f\"LR={lr}: média = {mean_acc:.3f}%, desvio = {std_acc:.3f}%\")"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Gráfico: acurácia média x learning rate\n", "plt.figure()\n", "x_pos = np.arange(len(lrs))\n", "plt.plot(x_pos, lr_means, marker=\"o\")\n", "plt.xticks(x_pos, [str(lr) for lr in lrs])\n", "plt.xlabel(\"Learning rate\")\n", "plt.ylabel(\"Acurácia média (%)\")\n", "plt.title(\"Acurácia vs Learning rate (5-fold)\")\n", "plt.grid(True)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 6. Experimento 3 – Variando o número de épocas\n", "\n", "Agora estudamos o efeito de **mais épocas de treino** na performance:\n", "\n", "- Mantemos:\n", "  - 1 bloco Conv+Pool  \n", "  - learning rate = 0.01  \n", "- Testamos:\n", "  - 10, 15, 20, 25, 30 épocas  \n", "\n", "Em seguida, veremos o gráfico de acurácia média por número de épocas."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["epochs_list = [10, 15, 20, 25, 30]\n", "ep_means = []\n", "ep_stds = []\n", "\n", "for ep in epochs_list:\n", "    mean_acc, std_acc = run_kfold(num_blocks=1, learning_rate=0.01, epochs=ep, verbose=0)\n", "    ep_means.append(mean_acc)\n", "    ep_stds.append(std_acc)\n", "    print(f\"Épocas={ep}: média = {mean_acc:.3f}%, desvio = {std_acc:.3f}%\")"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Gráfico: acurácia média x número de épocas\n", "plt.figure()\n", "x_pos = np.arange(len(epochs_list))\n", "plt.plot(x_pos, ep_means, marker=\"o\")\n", "plt.xticks(x_pos, [str(ep) for ep in epochs_list])\n", "plt.xlabel(\"Número de épocas\")\n", "plt.ylabel(\"Acurácia média (%)\")\n", "plt.title(\"Acurácia vs Número de épocas (5-fold)\")\n", "plt.grid(True)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 7. Conclusões\n", "\n", "A partir dos experimentos, você pode comparar com os resultados do artigo:\n", "\n", "- **Profundidade**: geralmente, 2 blocos Conv+Pool tendem a performar melhor que 1 ou 3 blocos.  \n", "- **Learning rate**: valores muito altos (ex: 0.1, 0.15) degradam a acurácia; algo próximo a **0.01** costuma ser mais estável.  \n", "- **Número de épocas**: aumentar as épocas nem sempre melhora indefinidamente; há um ponto de retorno decrescente, e o custo computacional cresce.  \n", "\n", "Você pode ajustar os hiperparâmetros e repetir os blocos de código dos experimentos para novas análises."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10"}}, "nbformat": 4, "nbformat_minor": 5}